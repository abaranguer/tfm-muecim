{"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"hUoGAD-Vv_Nt"}},{"cell_type":"markdown","source":["* Veure\n","https://discuss.huggingface.co/t/most-efficient-multi-label-classifier/9296/2\n","\n","* The Artificial Guy - MULTI-LABEL TEXT CLASSIFICATION USING BERT AND PYTORCH\n","https://www.youtube.com/watch?v=f-86-HcYYi8\n","\n","* Saurabh Anand - BERT for Multi-Label Classification\n","https://www.youtube.com/watch?v=JjcxZPNZbUY\n","\n","* KGP Talkie - 5 - Multi-Label Text Classification Model with DistilBERT and Hugging Face Transformers in PyTorch\n","https://www.youtube.com/watch?v=ZYc9za75Chk\n","\n","* Fine Tuning BERT for a Multi-Label Classification Problem on Colab - https://medium.com/@abdurhmanfayad_73788/fine-tuning-bert-for-a-multi-label-classification-problem-on-colab-5ca5b8759f3f\n","\n","* BERT and DistilBERT Models for NLP - https://medium.com/@kumari01priyanka/bert-and-distilbert-model-for-nlp-7352eb16915e\n","\n","* Choosing the Right Colab Runtime: A Guide for Data Scientists and Analysts - https://drlee.io/choosing-the-right-colab-runtime-a-guide-for-data-scientists-and-analysts-57ee7b7c9638\n","\n","* distilbert / distilbert-base-uncased - https://huggingface.co/distilbert/distilbert-base-uncased\n","\n","* \"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\" - https://arxiv.org/abs/1910.01108"],"metadata":{"id":"KkFdEWhYdBSu"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Bbt3PD8JQdGS","executionInfo":{"status":"ok","timestamp":1736707569316,"user_tz":-60,"elapsed":2572,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"da0d3d3b-4347-458c-bcc9-dcd4664512d8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/TFM-MUECIM/*.py /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.txt /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.csv /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/data/datasets/EURLEX57K/*.json /content"],"metadata":{"id":"NSTcMCSL-iyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8xMexEYKRZe","executionInfo":{"status":"ok","timestamp":1736707576280,"user_tz":-60,"elapsed":2423,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"ce6fbd22-cd7f-46bb-9fb2-03221d0c8abc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"]}]},{"cell_type":"code","source":["import sys\n","baseDir = '/content' #/drive/My Drive/TFM-MUECIM'\n","sys.path.append(baseDir)"],"metadata":{"id":"NB3DgnyvR_-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from tfm_LabelLoader import LabelLoader\n","from tfm_EURLEX57KDataset import EURLEX57KDataset\n","from torch.utils.data import DataLoader, random_split\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from transformers import EvalPrediction\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"],"metadata":{"id":"x0nf4jpHQTpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def countNonZeroItems(items):\n","    nonZero = torch.nonzero(items, as_tuple= True)\n","    return len(nonZero[0])"],"metadata":{"id":"wHYp827HSXSF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Segons el notebook:\n","Fine-tuning BERT (and friends) for multi-label text classification.ipynb\n","\n","https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=HgpKXDfvKBxn  "],"metadata":{"id":"qlpU-ZdpS8ju"}},{"cell_type":"code","source":["# ensures reproducibility\n","torch.manual_seed(0)"],"metadata":{"id":"kgtNCkrOTj6s","executionInfo":{"status":"ok","timestamp":1736707590408,"user_tz":-60,"elapsed":28,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"b70fcfe0-1ee5-4f58-bf67-aefd72441de7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7d7d86a9be90>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# load labels\n","labelLoader = LabelLoader(baseDir)\n","len(labelLoader.labels)"],"metadata":{"id":"lE6zncdpTxZ1","executionInfo":{"status":"ok","timestamp":1736707590408,"user_tz":-60,"elapsed":22,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"a133eb1f-14cf-4184-8574-c27256411c86","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7201"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["ds = EURLEX57KDataset(baseDir,'EURLEX57KDataFrame.csv')\n","trainData, valData, testData = random_split(ds, [45000, 6000, 6000])"],"metadata":{"id":"YI2J80j5dUxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set batch size\n","batchSize = 10\n","\n","# create dataloaders. In case we'll use a more classical pipeline approach\n","trainDataLoader = DataLoader(trainData, batch_size=batchSize, shuffle=True)\n","valDataLoader = DataLoader(valData, batch_size=batchSize, shuffle=True)\n","testDataLoader = DataLoader(testData, batch_size=batchSize, shuffle=True)"],"metadata":{"id":"elAZ80QQmyux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# iterate through val batches\n","for i, batch in enumerate(valDataLoader):\n","  print(f'Batch {i}: ')\n","  batchFileNames = batch.get('fileName')\n","  batchData = batch.get('input_ids')\n","  batchAttentionMasks = batch.get('attention_mask')\n","  batchLabels = batch.get('labels')\n","\n","  for elem in zip(batchFileNames, batchData, batchAttentionMasks, batchLabels):\n","    print(f'fileName: {elem[0]}')\n","    print(f'input_ids (5 first elements):\\n{elem[1][0:5]}')\n","    print(f'attention_masks (5 first elements):\\n{elem[2][0:5]}')\n","    print(f'Nonzero labels:{countNonZeroItems(elem[3])}\\n')\n","\n","  break\n","\n","print('Done!')"],"metadata":{"id":"X78654y-mkRt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736707599919,"user_tz":-60,"elapsed":31,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"902757b6-ad2f-4af0-97d7-0aee8002f953"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0: \n","fileName: data/datasets/EURLEX57K/train/32014D0241.json\n","input_ids (5 first elements):\n","tensor([ 2297,  1013, 22343,  1013,  7327])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:6\n","\n","fileName: data/datasets/EURLEX57K/train/32003R0205.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:6\n","\n","fileName: data/datasets/EURLEX57K/test/32002R1451.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:3\n","\n","fileName: data/datasets/EURLEX57K/train/32005D0607.json\n","input_ids (5 first elements):\n","tensor([2384, 1013, 3438, 2581, 1013])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:7\n","\n","fileName: data/datasets/EURLEX57K/test/32005R1989.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:5\n","\n","fileName: data/datasets/EURLEX57K/train/31987R4066.json\n","input_ids (5 first elements):\n","tensor([ 2473,  7816,  1006, 25212,  2278])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:4\n","\n","fileName: data/datasets/EURLEX57K/train/31995R1982.json\n","input_ids (5 first elements):\n","tensor([ 2473,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:6\n","\n","fileName: data/datasets/EURLEX57K/train/32010R0850.json\n","input_ids (5 first elements):\n","tensor([3222, 7816, 1006, 7327, 1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:6\n","\n","fileName: data/datasets/EURLEX57K/train/32011R0647.json\n","input_ids (5 first elements):\n","tensor([3222, 7816, 1006, 7327, 1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:9\n","\n","fileName: data/datasets/EURLEX57K/train/32008R0531.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:3\n","\n","Done!\n"]}]},{"cell_type":"code","source":["len(labelLoader.labels)"],"metadata":{"id":"hK2Xq-pgGNAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736707599920,"user_tz":-60,"elapsed":25,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"0d9c9dc6-f8a3-484a-ce0e-f634f062f2d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7201"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# bert huggingface pretrained model\n","from tfm_LabelIndex import LabelIndex\n","from transformers import AutoConfig, AutoModelForSequenceClassification\n","\n","labelIndex = LabelIndex(baseDir)\n","\n","# Gemini. Define a cache directory for Hugging Face models and ensure it exists.\n","cache_dir = os.path.join(baseDir, 'tfm_cache')\n","os.makedirs(cache_dir, exist_ok=True)\n","\n","# Load the configuration with the cache directory.\n","config = AutoConfig.from_pretrained(\n","    'distilbert-base-uncased',\n","    force_download=True,\n","    cache_dir=cache_dir,\n","    num_labels=len(labelLoader.labels),\n","    problem_type='multi_label_classification',\n","    id2label=labelIndex.id2label,\n","    label2id=labelIndex.label2id\n",")\n","\n","# Load the model with the configuration and cache directory.\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    'distilbert-base-uncased', # Changed to the correct model identifier\n","    config=config,  # Pass the configuration to the model.\n","    cache_dir=cache_dir  # Specify the cache directory again.\n",")"],"metadata":{"id":"W1-0V35mnfgT","colab":{"base_uri":"https://localhost:8080/","height":247,"referenced_widgets":["32a92c76dc114061a1cb78d9f7718da6","03386fac489c4beab70d5482f6f0dae8","b6d4f42baec346f781d2a20535c7ed25","e345002f20c341838fe3649e89842a1b","8c156b3894b540bfbb707c06f2a60d8b","4c76aeca1fbf434082b24816f8c0e7e1","9915aa6538ff402883f1007aa1c23918","8bb650e34ba044bc9122dc48bd952726","dd558da4f29c4c61892dbfa7f4ee1a04","885927d12f5d4ff8bb0775fa792c8241","7bcfb708692c4b14ad02567c944d3d1f","0bed61c5dc59449ca80cd1b003f31593","2f4cf0da9975460197869f5938cace74","bdc4def986214a04b2b4af393869db48","15f5f6855b1f463e96ff1dd3fd56aed9","8eb1c7c6eb964b8f837b45ad3fc32b54","15465671d95e438b99a4bced5a624dbc","9979066e35094782bfa8ba627e59e4bd","cb06b5f0fe7e4a0ab23f330961eecfef","3ae59de4f8d548a5991f9d322656170a","55b08df9159946fbbfb38137ef27232d","785ad019e3874fd2bb94703aa923a55b"]},"executionInfo":{"status":"ok","timestamp":1736707604774,"user_tz":-60,"elapsed":4871,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"ac85328d-150c-4f3a-aaf5-870666448b4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32a92c76dc114061a1cb78d9f7718da6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bed61c5dc59449ca80cd1b003f31593"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"id":"XpP9kR-7bA6i","executionInfo":{"status":"ok","timestamp":1736707604775,"user_tz":-60,"elapsed":16,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03172f6b-0464-4246-e363-743ec78fed8c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): DistilBertSdpaAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=7201, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# forward pass. no training. test case\n","item = trainData.__getitem__(0)\n","\n","outputs = model(\n","    input_ids=item['input_ids'][0:512].unsqueeze(0),\n","    attention_mask=item['attention_mask'][0:512].unsqueeze(0),\n","    labels=item['labels'].unsqueeze(0))"],"metadata":{"id":"PxmV0SKKz0Xm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs.logits[0]\n"],"metadata":{"id":"GHvBt-L5rxFO","executionInfo":{"status":"ok","timestamp":1736707605126,"user_tz":-60,"elapsed":19,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd3f8bd4-012a-4525-ba5f-485bf53cbd6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.0135,  0.2179, -0.0536,  ...,  0.1056, -0.0316, -0.1581],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n","# calculate metrics\n","\n","import numpy as np\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(outputs.logits[0])\n","threshold = 0.5\n","y_pred = np.zeros(probs.shape)\n","y_pred[np.where(probs >= threshold)] = 1\n","y_true = item['labels'].cpu().numpy() # Convert y_true to a NumPy array\n","f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","accuracy = accuracy_score(y_true, y_pred)\n","\n","metrics = {'f1': f1_micro_average,\n","           'roc_auc': roc_auc,\n","           'accuracy': accuracy}\n"],"metadata":{"id":"YfpY8psYMQDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics"],"metadata":{"id":"Pbpm8ZLqN8y6","executionInfo":{"status":"ok","timestamp":1736707605127,"user_tz":-60,"elapsed":13,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22b40ea9-c6da-4f6d-dc22-65eafb05a8e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'f1': 0.5036800444382724,\n"," 'roc_auc': 0.25201500833796553,\n"," 'accuracy': 0.5036800444382724}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n","\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","import torch\n","from transformers import TrainingArguments, Trainer\n","from transformers import EvalPrediction\n","\n","\n","def multi_label_metrics(predictions, labels, ):\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    y_pred = np.zeros(probs.shape)\n","    y_true = labels\n","    y_pred[np.where(probs >= 0.5)] = 1\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # define dictionary of metrics to return\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions,\n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds,\n","        labels=p.label_ids)\n","    return result\n","\n","def metricsForTestSet():\n","    predictions = trainer.predict(testData)\n","    preds = predictions.predictions[0] if isinstance(predictions.predictions, tuple) else predictions.predictions\n","    labels = predictions.label_ids\n","    testMetrics = multi_label_metrics(predictions=preds, labels=labels)\n","    print(testMetrics)\n","\n","# metric\n","metricName = 'f1'\n","\n","# training arguments\n","trainArgs = TrainingArguments(\n","    'tfm_oputput',\n","    report_to='none',  # deactivate wandb  reports. Alternative -> TensorBoard\n","    evaluation_strategy = 'epoch',\n","    save_strategy = 'epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batchSize,\n","    per_device_eval_batch_size=batchSize,\n","    num_train_epochs=1, # 1 epoch\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metricName)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=trainArgs,\n","    train_dataset=trainData,\n","    eval_dataset=valData,\n","    compute_metrics = compute_metrics,\n","    #data_collator = Data_Processing(),\n",")\n","\n","# API-KEY-WAND-LIBRARY: 1bb618394e7e44feab7f79534fa2be428243d1bb\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# Move the model to the correct device before training.\n","model.to(device)\n","\n","# epoch 0 - baseline\n","trainer.evaluate()\n","metricsForTestSet()\n","\n","# training\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"um7ZpE1y5xOi","outputId":"bad0669a-fcab-467e-ba05-af7ccaf89051"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 22:18]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='88' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  88/4500 10:43 < 9:10:22, 0.13 it/s, Epoch 0.02/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2029' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2029/4500 4:22:42 < 5:20:15, 0.13 it/s, Epoch 0.45/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["# https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch\n","import shutil\n","from datetime import datetime\n","\n","prefixDate = datetime.today().strftime('%Y%m%d')\n","fileName = f'{prefixDate}_tfm_model.pt'\n","modelFullPath = os.path.join(baseDir,fileName)\n","drivePath = '/content/drive/MyDrive/TFM-MUECIM'\n","destFullPath = os.path.join(drivePath,fileName)\n","torch.save(model, modelFullPath)\n","shutil.copyfile(modelFullPath, destFullPath)\n","\n","print 'Evaluate epoch'\n","trainer.evaluate()\n","metricsForTestSet():"],"metadata":{"id":"MGzXQk8FU7bp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m3uRVwYinGiI"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1ewwKVm9FPvrB9GaRPsXZ35y_xjFbwZRP","timestamp":1736724742726},{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1735915359838}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"32a92c76dc114061a1cb78d9f7718da6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03386fac489c4beab70d5482f6f0dae8","IPY_MODEL_b6d4f42baec346f781d2a20535c7ed25","IPY_MODEL_e345002f20c341838fe3649e89842a1b"],"layout":"IPY_MODEL_8c156b3894b540bfbb707c06f2a60d8b"}},"03386fac489c4beab70d5482f6f0dae8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c76aeca1fbf434082b24816f8c0e7e1","placeholder":"​","style":"IPY_MODEL_9915aa6538ff402883f1007aa1c23918","value":"config.json: 100%"}},"b6d4f42baec346f781d2a20535c7ed25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bb650e34ba044bc9122dc48bd952726","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd558da4f29c4c61892dbfa7f4ee1a04","value":483}},"e345002f20c341838fe3649e89842a1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_885927d12f5d4ff8bb0775fa792c8241","placeholder":"​","style":"IPY_MODEL_7bcfb708692c4b14ad02567c944d3d1f","value":" 483/483 [00:00&lt;00:00, 39.8kB/s]"}},"8c156b3894b540bfbb707c06f2a60d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c76aeca1fbf434082b24816f8c0e7e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9915aa6538ff402883f1007aa1c23918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bb650e34ba044bc9122dc48bd952726":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd558da4f29c4c61892dbfa7f4ee1a04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"885927d12f5d4ff8bb0775fa792c8241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bcfb708692c4b14ad02567c944d3d1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bed61c5dc59449ca80cd1b003f31593":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f4cf0da9975460197869f5938cace74","IPY_MODEL_bdc4def986214a04b2b4af393869db48","IPY_MODEL_15f5f6855b1f463e96ff1dd3fd56aed9"],"layout":"IPY_MODEL_8eb1c7c6eb964b8f837b45ad3fc32b54"}},"2f4cf0da9975460197869f5938cace74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15465671d95e438b99a4bced5a624dbc","placeholder":"​","style":"IPY_MODEL_9979066e35094782bfa8ba627e59e4bd","value":"model.safetensors: 100%"}},"bdc4def986214a04b2b4af393869db48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb06b5f0fe7e4a0ab23f330961eecfef","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ae59de4f8d548a5991f9d322656170a","value":267954768}},"15f5f6855b1f463e96ff1dd3fd56aed9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55b08df9159946fbbfb38137ef27232d","placeholder":"​","style":"IPY_MODEL_785ad019e3874fd2bb94703aa923a55b","value":" 268M/268M [00:01&lt;00:00, 253MB/s]"}},"8eb1c7c6eb964b8f837b45ad3fc32b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15465671d95e438b99a4bced5a624dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9979066e35094782bfa8ba627e59e4bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb06b5f0fe7e4a0ab23f330961eecfef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae59de4f8d548a5991f9d322656170a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55b08df9159946fbbfb38137ef27232d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"785ad019e3874fd2bb94703aa923a55b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}