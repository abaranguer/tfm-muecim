{"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"hUoGAD-Vv_Nt"}},{"cell_type":"markdown","source":["* Veure\n","https://discuss.huggingface.co/t/most-efficient-multi-label-classifier/9296/2\n","\n","* The Artificial Guy - MULTI-LABEL TEXT CLASSIFICATION USING BERT AND PYTORCH\n","https://www.youtube.com/watch?v=f-86-HcYYi8\n","\n","* Saurabh Anand - BERT for Multi-Label Classification\n","https://www.youtube.com/watch?v=JjcxZPNZbUY\n","\n","* KGP Talkie - 5 - Multi-Label Text Classification Model with DistilBERT and Hugging Face Transformers in PyTorch\n","https://www.youtube.com/watch?v=ZYc9za75Chk\n","\n","* Fine Tuning BERT for a Multi-Label Classification Problem on Colab - https://medium.com/@abdurhmanfayad_73788/fine-tuning-bert-for-a-multi-label-classification-problem-on-colab-5ca5b8759f3f\n","\n","* BERT and DistilBERT Models for NLP - https://medium.com/@kumari01priyanka/bert-and-distilbert-model-for-nlp-7352eb16915e\n","\n","* Choosing the Right Colab Runtime: A Guide for Data Scientists and Analysts - https://drlee.io/choosing-the-right-colab-runtime-a-guide-for-data-scientists-and-analysts-57ee7b7c9638\n","\n","* distilbert / distilbert-base-uncased - https://huggingface.co/distilbert/distilbert-base-uncased\n","\n","* \"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\" - https://arxiv.org/abs/1910.01108"],"metadata":{"id":"KkFdEWhYdBSu"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Bbt3PD8JQdGS","executionInfo":{"status":"ok","timestamp":1737589901011,"user_tz":-60,"elapsed":20867,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"42c5fd42-8ee8-4b7d-ee88-2f42f1290161","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/TFM-MUECIM/*.py /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.txt /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.csv /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.dat /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/*.pt /content\n","!cp /content/drive/MyDrive/TFM-MUECIM/data/datasets/EURLEX57K/*.json /content"],"metadata":{"id":"NSTcMCSL-iyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8xMexEYKRZe","executionInfo":{"status":"ok","timestamp":1737589102757,"user_tz":-60,"elapsed":2526,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"37e45e90-d3e9-47ed-c897-720579f19fa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"]}]},{"cell_type":"code","source":["import sys\n","baseDir = '/content' #/drive/My Drive/TFM-MUECIM'\n","sys.path.append(baseDir)"],"metadata":{"id":"NB3DgnyvR_-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Segons el notebook:\n","Fine-tuning BERT (and friends) for multi-label text classification.ipynb\n","\n","https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=HgpKXDfvKBxn  "],"metadata":{"id":"qlpU-ZdpS8ju"}},{"cell_type":"code","source":["import torch\n","\n","# ensures reproducibility\n","torch.manual_seed(0)"],"metadata":{"id":"kgtNCkrOTj6s","executionInfo":{"status":"ok","timestamp":1737589106562,"user_tz":-60,"elapsed":3815,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"87b23633-bac6-4c4a-90be-feab16c03ae3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e7679fa0790>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from tfm_EURLEX57KDataset import EURLEX57KDataset\n","from torch.utils.data import random_split\n","\n","ds = EURLEX57KDataset(baseDir,'ReducedEURLEX57KDataFrame.csv')\n","fullSetSize = ds.__len__()\n","trainSetSize = int(fullSetSize * 0.8)\n","valSetSize = int(fullSetSize * 0.1)\n","testSetSize = fullSetSize - trainSetSize - valSetSize\n","print(f'Full set size: {fullSetSize}')\n","print(f'Train set size: {trainSetSize}')\n","print(f'Validation set size: {valSetSize}')\n","print(f'Test set size: {testSetSize}')\n","trainData, valData, testData = random_split(\n","    ds,\n","    [trainSetSize, valSetSize, testSetSize]\n",")"],"metadata":{"id":"YI2J80j5dUxt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737589109595,"user_tz":-60,"elapsed":3041,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"e21a518c-3514-4874-d081-eccf46bc7604"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Full set size: 54382\n","Train set size: 43505\n","Validation set size: 5438\n","Test set size: 5439\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","# set batch size\n","batchSize = 10\n","\n","# create dataloaders. In case we'll use a more classical pipeline approach\n","trainDataLoader = DataLoader(trainData, batch_size=batchSize, shuffle=True)\n","valDataLoader = DataLoader(valData, batch_size=batchSize, shuffle=True)\n","testDataLoader = DataLoader(testData, batch_size=batchSize, shuffle=True)"],"metadata":{"id":"elAZ80QQmyux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def countNonZeroItems(items):\n","    nonZero = torch.nonzero(items, as_tuple= True)\n","    return len(nonZero[0])"],"metadata":{"id":"wHYp827HSXSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# iterate through val batches\n","for i, batch in enumerate(valDataLoader):\n","  print(f'Batch {i}: ')\n","  batchFileNames = batch.get('fileName')\n","  batchData = batch.get('input_ids')\n","  batchAttentionMasks = batch.get('attention_mask')\n","  batchLabels = batch.get('labels')\n","\n","  for elem in zip(batchFileNames, batchData, batchAttentionMasks, batchLabels):\n","    print(f'fileName: {elem[0]}')\n","    print(f'input_ids (5 first elements):\\n{elem[1][0:5]}')\n","    print(f'attention_masks (5 first elements):\\n{elem[2][0:5]}')\n","    print(f'Nonzero labels:{countNonZeroItems(elem[3])}\\n')\n","\n","  break\n","\n","print('Done!')"],"metadata":{"id":"X78654y-mkRt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737589109596,"user_tz":-60,"elapsed":16,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"dc338afb-eaca-4a69-f97a-b7487b7a36ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0: \n","fileName: data/datasets/EURLEX57K/train/32010R0503.json\n","input_ids (5 first elements):\n","tensor([3222, 7816, 1006, 7327, 1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:6\n","\n","fileName: data/datasets/EURLEX57K/train/32005R1314.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:3\n","\n","fileName: data/datasets/EURLEX57K/train/32013R0735.json\n","input_ids (5 first elements):\n","tensor([ 2473, 14972,  7816,  1006,  7327])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:1\n","\n","fileName: data/datasets/EURLEX57K/train/32001R1485.json\n","input_ids (5 first elements):\n","tensor([ 7816,  1006, 14925,  1007,  2053])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:2\n","\n","fileName: data/datasets/EURLEX57K/train/32007L0052.json\n","input_ids (5 first elements):\n","tensor([ 3222, 16449,  2289,  1013,  4720])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:2\n","\n","fileName: data/datasets/EURLEX57K/test/32007R1389.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:1\n","\n","fileName: data/datasets/EURLEX57K/train/31985R0143.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 25212,  2278])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:3\n","\n","fileName: data/datasets/EURLEX57K/train/31995R1202.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:4\n","\n","fileName: data/datasets/EURLEX57K/test/31997R2526.json\n","input_ids (5 first elements):\n","tensor([ 3222,  7816,  1006, 14925,  1007])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:2\n","\n","fileName: data/datasets/EURLEX57K/train/32014D0470.json\n","input_ids (5 first elements):\n","tensor([ 2297,  1013, 21064,  1013,  7327])\n","attention_masks (5 first elements):\n","tensor([1, 1, 1, 1, 1])\n","Nonzero labels:1\n","\n","Done!\n"]}]},{"cell_type":"code","source":["# bert huggingface pretrained model\n","import os\n","from transformers import AutoConfig\n","from transformers import DistilBertForSequenceClassification\n","from tfm_ReducedLabelIndex import LabelIndex\n","\n","labelIndex = LabelIndex(baseDir)\n","\n","# Gemini. Define a cache directory for Hugging Face models and ensure it exists.\n","cache_dir = os.path.join(baseDir, 'tfm_cache')\n","os.makedirs(cache_dir, exist_ok=True)\n","\n","# Load the configuration with the cache directory.\n","config = AutoConfig.from_pretrained(\n","    'distilbert-base-uncased',\n","    force_download=True,\n","    cache_dir=cache_dir,\n","    num_labels=labelIndex.numLabels,\n","    problem_type='multi_label_classification',\n","    id2label=labelIndex.id2label,\n","    label2id=labelIndex.label2id\n",")\n"],"metadata":{"id":"W1-0V35mnfgT","colab":{"base_uri":"https://localhost:8080/","height":247,"referenced_widgets":["4a050b3a4fb749fe8b4c547974ceecbd","5e65637b85de494c8ccf49ab0c881e4d","b1f2530fdd6f422b8f44a02f7d8006f7","8c362ac707db4ef4b11ba225a3b41230","ce55878010a149008203a912e83f35a0","61e33bbfbccf4fffa1644eb828126c64","bf51274bb19d4930b62ab3f326232b14","c98ed47c130946f9a003cac1fec306c7","57d9f27cdb9b4022bbdef5fe236d7c8a","3734d20aea4a454285c45e6b6d413676","3e144ff7d5d6494b93bfb5ac0350b387","97a37f533b054bfb8ecc075d11bcc855","ba6f8cb412224136bea7da52eaf14fad","b064e128ae954a09a26db16cbfab1747","89ae602620334606bc5842a32619e61f","be167c7b42fb442d90b8c716139ba28f","83e07d94c2924bd890ef5bfcba9b277e","d2da788ecab74a26975c4ef9eb0ff6e7","bb5b086f69ad44e882eb0a1cbc58ead3","1f098c05f8ac468d9a281a8c816c1952","3d07f10cdf354143ba074c9c62d69269","255e3be54e9a4a0f84df51677ba6c868"]},"executionInfo":{"status":"ok","timestamp":1737589126140,"user_tz":-60,"elapsed":16553,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"bb48cd15-d8b4-4bcb-91dd-03b80dd0d18c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a050b3a4fb749fe8b4c547974ceecbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a37f533b054bfb8ecc075d11bcc855"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["labelIndex.numLabels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYd7-d_j7lsS","executionInfo":{"status":"ok","timestamp":1737589126141,"user_tz":-60,"elapsed":20,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"823423b4-c4e5-4ca8-c7d8-344432312e6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["453"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 0 means pretrained fresh model\n","# 1, 2, 3 ... n. trained epochs from file\n","actual_epoch_training = 1\n","\n","if actual_epoch_training == 1:\n","  modelFile = '20250122_tfm_model.pt'"],"metadata":{"id":"OrovENWid0fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the model with the configuration and cache directory.\n","if actual_epoch_training == 0:\n","  model = DistilBertForSequenceClassification.from_pretrained(\n","    'distilbert-base-uncased', # Changed to the correct model identifier\n","    config=config,  # Pass the configuration to the model.\n","    cache_dir=cache_dir  # Specify the cache directory again.\n","  )\n","else:\n","  model = torch.load(os.path.join(baseDir,modelFile))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"lNuldwVEdl1B","executionInfo":{"status":"error","timestamp":1737590873895,"user_tz":-60,"elapsed":228,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"46fc59de-5337-42fb-ad18-150eb9c420d7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-31c8f40782bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   )\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","source":["model"],"metadata":{"id":"XpP9kR-7bA6i","executionInfo":{"status":"ok","timestamp":1737589126142,"user_tz":-60,"elapsed":15,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c8b2182-316b-42c2-8a3a-aa2b6290ce4f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): DistilBertSdpaAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=453, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# forward pass. no training. test case\n","item = trainData.__getitem__(0)\n","\n","outputs = model(\n","    input_ids=item['input_ids'][0:512].unsqueeze(0),\n","    attention_mask=item['attention_mask'][0:512].unsqueeze(0),\n","    labels=item['labels'].unsqueeze(0))"],"metadata":{"id":"PxmV0SKKz0Xm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs.logits[0]\n"],"metadata":{"id":"GHvBt-L5rxFO","executionInfo":{"status":"ok","timestamp":1737589126366,"user_tz":-60,"elapsed":17,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5d16c08-e775-4b0a-d269-b0bf5fd4907a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.0670,  0.0106, -0.0178,  0.0672,  0.0900, -0.0588, -0.0868, -0.0058,\n","         0.1310,  0.0776,  0.1465,  0.0925, -0.0327,  0.0436,  0.0823, -0.0458,\n","        -0.0639,  0.0312,  0.0283, -0.0678, -0.0173, -0.1745, -0.1317,  0.0623,\n","         0.0374,  0.0376, -0.0857, -0.0313, -0.0792, -0.1140,  0.0031,  0.0194,\n","        -0.0044,  0.0173, -0.1229, -0.0997, -0.0439, -0.0517,  0.0658, -0.0061,\n","        -0.0298, -0.0333,  0.1592,  0.1266,  0.0595,  0.0221,  0.0656,  0.0618,\n","        -0.0576,  0.0350, -0.0338,  0.0583,  0.0084, -0.0634,  0.1000, -0.1101,\n","        -0.0085, -0.0699, -0.0091, -0.0269,  0.0352, -0.0005, -0.1170, -0.0764,\n","        -0.0155, -0.0036, -0.0050,  0.0590,  0.0065,  0.1318,  0.0317, -0.0406,\n","         0.0553,  0.0642, -0.0306, -0.0014, -0.0914,  0.0121, -0.0266,  0.0830,\n","        -0.0558,  0.0037, -0.0013,  0.0489, -0.0113,  0.1120, -0.0187,  0.0094,\n","         0.1167,  0.0388, -0.0131, -0.0362, -0.0226, -0.1158,  0.1317,  0.0080,\n","        -0.0316, -0.0126, -0.0353, -0.0248,  0.1086,  0.0137,  0.1640,  0.0154,\n","         0.0169,  0.0100, -0.0013,  0.0107, -0.1144, -0.0903, -0.0483, -0.0502,\n","        -0.0174, -0.0280, -0.0754, -0.0325, -0.1599, -0.0959,  0.0549,  0.0800,\n","        -0.0778,  0.0325,  0.0614,  0.0020,  0.0752, -0.0973, -0.0539,  0.0219,\n","         0.0191,  0.0491, -0.0537, -0.0544,  0.0491,  0.0290, -0.0418,  0.0622,\n","         0.0990, -0.0777, -0.0425, -0.0807,  0.0734,  0.0183, -0.0010,  0.0340,\n","        -0.0312,  0.0110,  0.0957, -0.0062,  0.0463,  0.0014,  0.0714,  0.0174,\n","         0.0352, -0.0706, -0.0104, -0.0465, -0.0407, -0.0053,  0.0618,  0.0287,\n","         0.1148,  0.0060,  0.0564, -0.0583, -0.0515, -0.0162, -0.1595, -0.0180,\n","         0.0566,  0.0478,  0.1826,  0.0390, -0.0181, -0.0236,  0.0316, -0.0914,\n","         0.0666,  0.0036,  0.1212,  0.0535,  0.0490, -0.0609, -0.0512, -0.1327,\n","        -0.0989, -0.0582,  0.1904,  0.0244,  0.0822,  0.0107, -0.1229, -0.0717,\n","         0.0042, -0.1192, -0.0799,  0.0300,  0.0504,  0.0081, -0.0159, -0.1475,\n","        -0.1131, -0.2313, -0.0696,  0.0113,  0.0016,  0.1040, -0.1510, -0.0443,\n","        -0.0462, -0.0457,  0.0839,  0.0027,  0.0877, -0.1381,  0.1386, -0.1035,\n","         0.0504, -0.0093, -0.1207, -0.0694, -0.0609,  0.0768,  0.0361, -0.0881,\n","        -0.0631,  0.0428,  0.0350,  0.0070,  0.0030, -0.0796, -0.0518, -0.0732,\n","        -0.0733, -0.0627, -0.0029, -0.1799,  0.0096, -0.0284, -0.0174, -0.0073,\n","        -0.1142,  0.0709,  0.0400, -0.0697, -0.1090,  0.1064,  0.0646,  0.0301,\n","        -0.1004, -0.1238,  0.0044,  0.0371, -0.0143,  0.1343, -0.1018,  0.0497,\n","        -0.0123, -0.1009, -0.0319,  0.0021,  0.1624,  0.0308,  0.0202,  0.0297,\n","         0.0215, -0.0307,  0.0741,  0.0230,  0.0855, -0.0932, -0.0472,  0.0149,\n","        -0.0707, -0.0943, -0.0934,  0.0006, -0.0516,  0.0507,  0.0292, -0.0605,\n","        -0.0403, -0.0514,  0.1141,  0.1369,  0.1189, -0.0542, -0.0349,  0.0030,\n","         0.0747,  0.0027,  0.0175,  0.0660, -0.0415, -0.0344, -0.0534,  0.0874,\n","         0.0507,  0.0565,  0.0525,  0.0256,  0.1243,  0.0083,  0.0518, -0.0111,\n","        -0.1250,  0.0124, -0.0464,  0.0991, -0.0534, -0.0431, -0.0305,  0.1218,\n","         0.0315, -0.0535, -0.0170, -0.0243,  0.0182,  0.0136, -0.0446, -0.0181,\n","        -0.0756,  0.0749,  0.0182,  0.0881,  0.0688, -0.1190,  0.0024,  0.0200,\n","        -0.0351, -0.0541, -0.0555,  0.0187,  0.0257, -0.0959, -0.0586,  0.0353,\n","        -0.0035, -0.0188,  0.0145,  0.0160,  0.0308,  0.0687, -0.0474, -0.0063,\n","        -0.0554, -0.0026, -0.1405, -0.0033, -0.0084,  0.0096, -0.0464, -0.0122,\n","        -0.0347,  0.0127,  0.0598,  0.1373,  0.0882,  0.0673,  0.0092,  0.0116,\n","         0.0126,  0.0196, -0.0949,  0.0755, -0.0785,  0.1015,  0.0066, -0.0734,\n","        -0.1262,  0.0075,  0.1109,  0.0065,  0.0393,  0.0146,  0.1106,  0.1254,\n","         0.1248, -0.1020, -0.1138,  0.0144,  0.0809, -0.0973,  0.0317,  0.0289,\n","        -0.0392, -0.1944,  0.1315,  0.0240,  0.0025,  0.0371, -0.0928,  0.0321,\n","         0.0562, -0.0495,  0.0925, -0.1021,  0.0995,  0.0736, -0.0439,  0.0364,\n","        -0.0418,  0.0466, -0.1052, -0.0207, -0.0203,  0.0264,  0.0047, -0.0957,\n","        -0.0100,  0.0346,  0.0213,  0.0868,  0.0185, -0.0171,  0.0248,  0.1286,\n","        -0.1740, -0.0117, -0.0168, -0.1205,  0.0578, -0.1204,  0.0764,  0.0187,\n","         0.0474, -0.1105, -0.1814, -0.0014, -0.1109, -0.0746, -0.0321, -0.0591,\n","        -0.0798,  0.0121,  0.1827, -0.0327, -0.0840, -0.0103, -0.0714, -0.0664,\n","        -0.1084, -0.0888, -0.1095, -0.0373,  0.0508,  0.0169,  0.0743, -0.0254,\n","         0.0235, -0.0933,  0.1136, -0.0884, -0.0791],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n","# calculate metrics\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(outputs.logits[0])\n","threshold = 0.5\n","y_pred = np.zeros(probs.shape)\n","y_pred[np.where(probs >= threshold)] = 1\n","y_true = item['labels'].cpu().numpy() # Convert y_true to a NumPy array\n","f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","accuracy = accuracy_score(y_true, y_pred)\n","\n","metrics = {'f1': f1_micro_average,\n","           'roc_auc': roc_auc,\n","           'accuracy': accuracy}\n"],"metadata":{"id":"YfpY8psYMQDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics  # code test"],"metadata":{"id":"Pbpm8ZLqN8y6","executionInfo":{"status":"ok","timestamp":1737589126366,"user_tz":-60,"elapsed":13,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bbcac4e4-4ccc-48d0-8d28-ccf2862fa12a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'f1': 0.5055187637969095,\n"," 'roc_auc': 0.752212389380531,\n"," 'accuracy': 0.5055187637969095}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n","# https://towardsdatascience.com/evaluating-multi-label-classifiers-a31be83da6ea\n","\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","import torch\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from transformers import EvalPrediction\n","\n","\n","def multi_label_metrics(predictions, labels, ):\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    y_pred = np.zeros(probs.shape)\n","    y_true = labels\n","    y_pred[np.where(probs >= 0.5)] = 1\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # define dictionary of metrics to return\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions,\n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds,\n","        labels=p.label_ids)\n","    return result\n","\n","def metricsForTestSet():\n","    predictions = trainer.predict(testData)\n","    preds = predictions.predictions[0] if isinstance(predictions.predictions, tuple) else predictions.predictions\n","    labels = predictions.label_ids\n","    testMetrics = multi_label_metrics(predictions=preds, labels=labels)\n","    print(testMetrics)\n","\n","# metric\n","metricName = 'f1'\n","\n","# training arguments\n","trainArgs = TrainingArguments(\n","    'tfm_oputput',\n","    report_to='none',  # deactivate wandb  reports. Alternative -> TensorBoard\n","    evaluation_strategy = 'epoch',\n","    save_strategy = 'epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batchSize,\n","    per_device_eval_batch_size=batchSize,\n","    num_train_epochs=1, # 1 epoch\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metricName)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=trainArgs,\n","    train_dataset=trainData,\n","    eval_dataset=valData,\n","    compute_metrics = compute_metrics,\n","    #data_collator = Data_Processing(),\n",")\n","\n","# API-KEY-WAND-LIBRARY: 1bb618394e7e44feab7f79534fa2be428243d1bb\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# Move the model to the correct device before training.\n","model.to(device)\n","\n","# epoch 0 - baseline\n","print('Begin epoch train session - trainer evaluate')\n","trainer.evaluate()\n","\n","print('Metrics for test set (before train)')\n","metricsForTestSet()\n","\n","# training\n","print('Epoch train.')\n","trainer.train()\n","print('Epoch train done.')\n","\n","print('End epoch train session - trainer evaluate')\n","trainer.evaluate()\n","\n","print('Metrics for test set (after train)')\n","metricsForTestSet()\n","\n","print('End epoch train session')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"um7ZpE1y5xOi","outputId":"20d085ea-db69-4644-a320-7f066801f02b","executionInfo":{"status":"ok","timestamp":1737589710699,"user_tz":-60,"elapsed":584340,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Begin epoch train session - trainer evaluate\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Metrics for test set (before train)\n","{'f1': 0.015408181277445143, 'roc_auc': 0.5040830380347188, 'accuracy': 0.0}\n","Epoch train.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4351' max='4351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4351/4351 08:11, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Model Preparation Time</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.027800</td>\n","      <td>0.026416</td>\n","      <td>0.001500</td>\n","      <td>0.302176</td>\n","      <td>0.590985</td>\n","      <td>0.010666</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch train done.\n","End epoch train session - trainer evaluate\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Metrics for test set (after train)\n","{'f1': 0.2995355358864254, 'roc_auc': 0.5900190412379849, 'accuracy': 0.013973156830299687}\n","End epoch train session\n"]}]},{"cell_type":"code","source":["# https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch\n","import shutil\n","from datetime import datetime\n","\n","prefixDate = datetime.today().strftime('%Y%m%d')\n","fileName = f'{prefixDate}_tfm_model.pt'\n","modelFullPath = os.path.join(baseDir,fileName)\n","drivePath = '/content/drive/MyDrive/TFM-MUECIM'\n","destFullPath = os.path.join(drivePath,fileName)\n","print('Save model after epoch train session')\n","torch.save(model, modelFullPath)\n","shutil.copyfile(modelFullPath, destFullPath)\n","\n"],"metadata":{"id":"MGzXQk8FU7bp","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1737589734592,"user_tz":-60,"elapsed":1216,"user":{"displayName":"Albert Baranguer","userId":"04291152240601656998"}},"outputId":"de71a02e-a873-44e5-8c9c-ac657acc9816"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Save model after epoch train session\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/TFM-MUECIM/20250122_tfm_model.pt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]}],"metadata":{"colab":{"provenance":[{"file_id":"1A_S9R8tB9mHXPU4--CYOkpScOefFhxq0","timestamp":1737591802372},{"file_id":"1ewwKVm9FPvrB9GaRPsXZ35y_xjFbwZRP","timestamp":1736724742726},{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1735915359838}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4a050b3a4fb749fe8b4c547974ceecbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e65637b85de494c8ccf49ab0c881e4d","IPY_MODEL_b1f2530fdd6f422b8f44a02f7d8006f7","IPY_MODEL_8c362ac707db4ef4b11ba225a3b41230"],"layout":"IPY_MODEL_ce55878010a149008203a912e83f35a0"}},"5e65637b85de494c8ccf49ab0c881e4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e33bbfbccf4fffa1644eb828126c64","placeholder":"â€‹","style":"IPY_MODEL_bf51274bb19d4930b62ab3f326232b14","value":"config.json:â€‡100%"}},"b1f2530fdd6f422b8f44a02f7d8006f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c98ed47c130946f9a003cac1fec306c7","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d9f27cdb9b4022bbdef5fe236d7c8a","value":483}},"8c362ac707db4ef4b11ba225a3b41230":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3734d20aea4a454285c45e6b6d413676","placeholder":"â€‹","style":"IPY_MODEL_3e144ff7d5d6494b93bfb5ac0350b387","value":"â€‡483/483â€‡[00:00&lt;00:00,â€‡43.6kB/s]"}},"ce55878010a149008203a912e83f35a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e33bbfbccf4fffa1644eb828126c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf51274bb19d4930b62ab3f326232b14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c98ed47c130946f9a003cac1fec306c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d9f27cdb9b4022bbdef5fe236d7c8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3734d20aea4a454285c45e6b6d413676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e144ff7d5d6494b93bfb5ac0350b387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97a37f533b054bfb8ecc075d11bcc855":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba6f8cb412224136bea7da52eaf14fad","IPY_MODEL_b064e128ae954a09a26db16cbfab1747","IPY_MODEL_89ae602620334606bc5842a32619e61f"],"layout":"IPY_MODEL_be167c7b42fb442d90b8c716139ba28f"}},"ba6f8cb412224136bea7da52eaf14fad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83e07d94c2924bd890ef5bfcba9b277e","placeholder":"â€‹","style":"IPY_MODEL_d2da788ecab74a26975c4ef9eb0ff6e7","value":"model.safetensors:â€‡100%"}},"b064e128ae954a09a26db16cbfab1747":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5b086f69ad44e882eb0a1cbc58ead3","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f098c05f8ac468d9a281a8c816c1952","value":267954768}},"89ae602620334606bc5842a32619e61f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d07f10cdf354143ba074c9c62d69269","placeholder":"â€‹","style":"IPY_MODEL_255e3be54e9a4a0f84df51677ba6c868","value":"â€‡268M/268Mâ€‡[00:01&lt;00:00,â€‡234MB/s]"}},"be167c7b42fb442d90b8c716139ba28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e07d94c2924bd890ef5bfcba9b277e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2da788ecab74a26975c4ef9eb0ff6e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb5b086f69ad44e882eb0a1cbc58ead3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f098c05f8ac468d9a281a8c816c1952":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d07f10cdf354143ba074c9c62d69269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"255e3be54e9a4a0f84df51677ba6c868":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}